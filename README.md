# Malware URL Lookup Service

This is a simple web service to check if a URL is malicious.

## Requirements

- Python 3.x
- Flask
- Flask-Limiter
- SQLite3

## Installation

1. Clone the repository:
    ```bash
    git clone https://github.com/loganausmus/logan-malware-exercise.git
    cd logan-malware-exercise
    ```

2. Create a virtual environment and install dependencies:
    ```bash
    python -m venv venv
    source venv/bin/activate
    pip install -r requirements.txt
    ```

3. Initialize the database and populate it with sample data:
    ```bash
    python database.py
    ```

4. Run the application:
    ```bash
    python app.py
    ```

## API

### Check URL

- **URL:** `/v1/urlinfo/{resource_url_with_query_string}`
- **Method:** `GET`
- **Response:**
    ```json
    {
        "url": "http://example.com",
        "is_malicious": false
    }
    ```

## Running Tests

1. Run the tests:
    ```bash
    python -m unittest discover tests
    ```

## Database

### Schema

- **Table:** `malware_urls`
  - `id`: INTEGER PRIMARY KEY AUTOINCREMENT
  - `url`: TEXT NOT NULL
  - `is_malicious`: BOOLEAN NOT NULL

### Sample Data

The database is populated with the following sample data:
- Safe URLs: `http://example.com`, `http://test.com`, `http://safeurl.com`, `http://harmless.com`, `http://benign.com`
- Malicious URLs: `http://malicious.com`, `http://badurl.com`, `http://dangerous.com`, `http://evil.com`, `http://threat.com`

## Rate Limiting

The application uses Flask-Limiter to limit the number of requests to the API:
- **Global Limits:** 200 requests per day and 50 requests per hour per client.
- **Endpoint Limits:** 10 requests per minute per client on `/v1/urlinfo/{resource_url_with_query_string}`.

## Bonus Implementation

### Scaling Beyond Memory Capacity
To handle an infinitely growing URL list, I implemented a database solution using SQLite. For even larger datasets, would likely transition to a more scalable database such as PostgreSQL, Amazon DynamoDB

### Handling High Number of Requests
To address capacity constraints due to high request volumes, I implemented rate limiting using Flask-Limiter. This ensures the system can handle traffic efficiently by limiting the number of requests per client.

### Strategies for Updating the Service with New URLs
To handle frequent and high-volume URL updates (up to 5000 URLs every 10 minutes), consider the following strategies:

1. **Batch Processing:** Accumulate incoming URLs and update the database in batches at regular intervals (e.g., every 10 minutes).
   
2. **Using a Scheduler:** Implement a background scheduler, such as APScheduler, to periodically fetch and update URLs. This ensures updates are handled efficiently and without manual intervention.
    ```python
    from apscheduler.schedulers.background import BackgroundScheduler

    def fetch_new_urls():
        new_urls = [
            ('http://newexample.com', False),
            ('http://newmalicious.com', True),
            # Add more URLs as needed
        ]
        database.batch_update_urls(new_urls)

    scheduler = BackgroundScheduler()
    scheduler.add_job(fetch_new_urls, 'interval', minutes=10)
    scheduler.start()

    if __name__ == '__main__':
        try:
            app.run(debug=True)
        except (KeyboardInterrupt, SystemExit):
            scheduler.shutdown()
    ```
